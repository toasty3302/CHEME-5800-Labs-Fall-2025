{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397ee050-19dc-4149-ad23-ac70b9408191",
   "metadata": {},
   "source": [
    "# L7b: Estimating Single Index Models (SIMs) from Historical Data\n",
    "In this lab, students will estimate single index models from historical data. Single index models are widely used in finance to model the returns of assets based on their relationship with a market index.\n",
    "\n",
    "> __Learning Objectives:__\n",
    ">\n",
    "> By the end of this example, you will be able to:\n",
    "> * **Transform historical price data into growth rate matrices** - We will compute continuously compounded growth rates from daily S&P500 stock prices spanning 2014-2024 and verify full column rank (424 independent firms) in the resulting matrix, gaining hands-on experience structuring financial time series for econometric analysis.\n",
    ">\n",
    "> * **Estimate single index model parameters and quantify uncertainty** - We will apply the normal equations approach to estimate alpha and beta parameters using ordinary least squares, then compute residual variance, standard errors, and 95% confidence intervals to assess the statistical significance of our parameter estimates.\n",
    ">\n",
    "> * **Apply SVD-based estimation for numerical robustness** - We will decompose the design matrix using Singular Value Decomposition and reconstruct parameters via the pseudoinverse formula $\\hat{\\mathbf{\\theta}} = \\sum_{i=1}^{r}(\\mathbf{u}_i^{\\top}\\mathbf{y}/\\sigma_i)\\mathbf{v}_i$, learning why SVD provides superior numerical stability compared to direct matrix inversion when dealing with potential multicollinearity.\n",
    "\n",
    "Let's go!\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a8de6",
   "metadata": {},
   "source": [
    "## Setup, Data, and Prerequisites\n",
    "First, we set up the computational environment by including the `Include.jl` file and loading any needed resources.\n",
    "\n",
    "> __Include:__ The [`include(...)` command](https://docs.julialang.org/en/v1/base/base/#include) evaluates the contents of the input source file, `Include.jl`, in the notebook's global scope. The `Include.jl` file sets paths, loads required external packages, etc. For additional information on functions and types used in this material, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/). \n",
    "\n",
    "Let's set up our code environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310793c4-6b3d-47c2-9107-0c22fca06279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(joinpath(@__DIR__, \"Include.jl\")); # include the Include.jl file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444ebe9b",
   "metadata": {},
   "source": [
    "In addition to standard Julia libraries, we'll also use [the `VLDataScienceMachineLearningPackage.jl` package](https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl). Check out [the documentation](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/) for more information on the functions, types, and data used in this material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba37ea1d-abdd-4c5f-a809-7b83f74d73fb",
   "metadata": {},
   "source": [
    "### Data\n",
    "We gathered a daily open-high-low-close dataset for each firm in the [S&P500](https://en.wikipedia.org/wiki/S%26P_500) from `01-03-2014` until `12-31-2024`, along with data for a few exchange-traded funds and volatility products during that time. \n",
    "\n",
    "Let's load the `original_dataset::DataFrame` by calling [the `MyTrainingMarketDataSet()` function](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/data/#VLDataScienceMachineLearningPackage.MyTrainingMarketDataSet) and remove firms that do not have the maximum number of trading days. The cleaned dataset $\\mathcal{D}$ will be stored in the `dataset` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74fab494-70b1-44da-b161-3dd6f0c10acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_dataset = MyTrainingMarketDataSet() |> x-> x[\"dataset\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db3e050-1d1d-4b3b-87e6-4bd21e3950a1",
   "metadata": {},
   "source": [
    "Not all tickers in our dataset have the maximum number of trading days for various reasons, e.g., acquisition or de-listing events. Let's collect only those tickers with the maximum number of trading days.\n",
    "\n",
    "First, let's compute the number of records for a firm that we know has a maximum value, e.g., `AAPL`, and save that value in the `maximum_number_trading_days::Int64` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ea15f76-b5b5-48af-b65b-6c4237249903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2767"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum_number_trading_days = original_dataset[\"AAPL\"] |> nrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048f994-8a1b-404e-a6a4-9ab1d1bf8176",
   "metadata": {},
   "source": [
    "Now, let's iterate through our data and collect only tickers with `maximum_number_trading_days` records. Save that data in the `dataset::Dict{String,DataFrame}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d09a5526-dc58-4d9d-b039-26d8488a0a37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dict{String,DataFrame}();\n",
    "for (ticker,data) ∈ original_dataset\n",
    "    if (nrow(data) == maximum_number_trading_days)\n",
    "        dataset[ticker] = data;\n",
    "    end\n",
    "end\n",
    "dataset;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65219967-6422-4882-ad55-6ff9ee541429",
   "metadata": {},
   "source": [
    "How many firms do we have with the full number of trading days? Let's use [the `length(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.length) - notice this works for dictionaries, in addition to arrays, sets, and other collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96aae951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(dataset) # tells us how many keys are in the dictionary (how many firms in our dataset?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f8d65",
   "metadata": {},
   "source": [
    "Finally, let's get a list of the firms in our cleaned dataset (and sort them alphabetically). We store the sorted firm ticker symbols in the `list_of_tickers::Array{String,1}` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ade9b30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424-element Vector{String}:\n",
       " \"A\"\n",
       " \"AAL\"\n",
       " \"AAP\"\n",
       " \"AAPL\"\n",
       " \"ABBV\"\n",
       " \"ABT\"\n",
       " \"ACN\"\n",
       " \"ADBE\"\n",
       " \"ADI\"\n",
       " \"ADM\"\n",
       " \"ADP\"\n",
       " \"ADSK\"\n",
       " \"AEE\"\n",
       " ⋮\n",
       " \"WST\"\n",
       " \"WU\"\n",
       " \"WY\"\n",
       " \"WYNN\"\n",
       " \"XEL\"\n",
       " \"XOM\"\n",
       " \"XRAY\"\n",
       " \"XYL\"\n",
       " \"YUM\"\n",
       " \"ZBRA\"\n",
       " \"ZION\"\n",
       " \"ZTS\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tickers = keys(dataset) |> collect |> sort # list of firm \"ticker\" symbols in alphabetical order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf8cb7",
   "metadata": {},
   "source": [
    "### Compute the growth rate matrix\n",
    "Next, let's compute the growth rate array which contains, for each day and each firm in our dataset, the value of the growth rate between time $j$ and $j-1$. \n",
    "\n",
    ">  __Continuously Compounded Growth Rate (CCGR)__\n",
    ">\n",
    "> Let's assume a model of the share price of firm $i$ is governed by an expression of the form:\n",
    ">$$\n",
    "\\begin{align*}\n",
    "S^{(i)}_{j} &= S^{(i)}_{j-1}\\;\\exp\\left(g^{(i)}_{j,j-1}\\Delta{t}_{j}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "> where $S^{(i)}_{j-1}$ denotes the share price of firm $i$ at time index $j-1$, $S^{(i)}_{j}$ denotes the share price of firm $i$ at time index $j$, and $\\Delta{t}_{j} = t_{j} - t_{j-1}$ denotes the length of a time step (units: years) between time index $j-1$ and $j$. The value we are going to estimate is the growth rate $g^{(i)}_{j,j-1}$ (units: inverse years) for each firm $i$, and each time step in the dataset.\n",
    "\n",
    "We've implemented [the `log_growth_matrix(...)` function](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/data/#VLDataScienceMachineLearningPackage.log_growth_matrix) which takes the cleaned dataset and a list of ticker symbols, and returns the growth rate array. Each row of the growth rate array is a time step, while each column corresponds to a firm from the `list_of_tickers::Array{String,1}` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e35c1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2766×424 Matrix{Float64}:\n",
       " -0.877554    6.28105    -2.87097     …  -0.755391   0.245894  -1.00527\n",
       "  2.81626     1.07149     1.39239         2.13832   -0.80279    0.986468\n",
       "  3.31305     0.855597    0.00536803      0.109877   1.191     -2.58144\n",
       "  0.646425   17.2599      1.69215         0.274716   3.1593    -0.368228\n",
       "  1.81609     2.57961     3.31924         0.621677  -2.1687     4.40309\n",
       "  0.61383    -3.96384    -0.79278     …  -0.862739  -1.90977   -3.11624\n",
       "  2.86071    -0.483751    4.84573         1.7657    -1.77685   -1.0896\n",
       "  2.04671     1.0135      1.90809         1.67597    4.44984   -0.137819\n",
       "  1.31289     1.67413     0.107259       -1.50708   -2.13696    1.43784\n",
       "  1.22016     6.12957     0.932578       -1.53202    2.87784   -1.43626\n",
       " -0.437668    4.87009     1.00774     …  -0.321261   9.50827   -3.00873\n",
       "  1.36281     3.61317    -2.34776         0.710613   4.52223    0.340531\n",
       " -4.73904     1.38585    -3.01624        -2.15245   -6.64907    1.40612\n",
       "  ⋮                                   ⋱                        \n",
       " -4.43047    -6.74816    -0.498579       -2.15215   -4.19105   -0.651582\n",
       " -1.24943    -4.03197     4.29843     …   2.1597    -0.456993  -1.70346\n",
       " -1.7614     -1.95521    -1.19395        -5.90153   -5.03854   -7.78914\n",
       " -4.36889     3.84443    -2.37452        -4.26011   -9.17906   -3.94641\n",
       " -2.51182    -2.60891   -10.1209         -3.03895   -7.07468   -7.14019\n",
       "  2.21355     4.15066     7.27678         3.59833    3.76887    0.726527\n",
       " -0.333723    3.35696     0.139017    …  -0.872951   2.50878   -1.40547\n",
       "  2.6692     -0.469264    1.84185         2.08796    1.97562    0.830608\n",
       " -0.0573992   2.62923     4.65626         1.37413    2.20713    1.01026\n",
       " -0.374809    0.285437   -1.69274        -4.26156   -2.16696   -0.798327\n",
       " -1.50428     3.17759     8.8066         -3.68058   -1.30045   -2.98592\n",
       " -0.31183    -0.241574    7.6085      …   0.983071   0.165185   0.152788"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth_rate_array = let\n",
    "\n",
    "    # initialize -\n",
    "    τ = (1/252); # time-step one-day in units of years (trading year is 252 days)\n",
    "    r̄ = 0.0; # assume the risk-free rate is 0\n",
    "\n",
    "    # compute the growth matrix -\n",
    "    growth_rate_array = log_growth_matrix(dataset, list_of_tickers, Δt = τ, \n",
    "        risk_free_rate = r̄); # other optional parameters are at their defaults\n",
    "\n",
    "    growth_rate_array; # return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eff75e",
   "metadata": {},
   "source": [
    "> **Growth Rate Matrix Structure**\n",
    ">\n",
    "> The `growth_rate_array` is a matrix $\\mathbf{G} \\in \\mathbb{R}^{m \\times n}$ where each **row** represents a trading day (time step) in our dataset, each **column** represents a firm from the S&P500, and each **element** $G_{i,j}$ contains the continuously compounded growth rate for firm $j$ on day $i$.\n",
    "\n",
    "The matrix has 424 firms (columns) and there are $T-1$ = 2,766 trading days (rows), capturing the daily growth rate dynamics of the S&P500 components from 2014 to 2024. Is there redundancy in the data?\n",
    "\n",
    "Let's check the rank of the growth rate array using [the `rank(...)` function](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.rank):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae70477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank(growth_rate_array) # tells us the rank of the growth rate array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fba90b",
   "metadata": {},
   "source": [
    "The growth rate matrix has **full column rank** (rank = 424), which means that all 424 firms contribute independent information to the dataset. \n",
    "\n",
    "> __Why is this significant?__ This tells us that no firm's growth pattern can be perfectly predicted from the others. Each stock brings unique behavior to the market, even though there may be strong correlations between them.\n",
    "\n",
    "Now, let's build a single index model for a single firm, to see how this works.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc53b827",
   "metadata": {},
   "source": [
    "## Task 1: Build a single index model for a test firm\n",
    "In this task, let's build a single index model for a test firm, so that we can see how to set up this calculation and test that it works. \n",
    "\n",
    "> __Single Index Model (SIM)__\n",
    "> \n",
    "> Single index models are factor models that consider only the return (growth) of the market factor. These models were originally developed by Sharpe, 1963: [Sharpe, William F. (1963). \"A Simplified Model for Portfolio Analysis\". Management Science, 9(2): 277-293. doi:10.1287/mnsc.9.2.277.](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.9.2.277)\n",
    ">\n",
    "> Suppose the growth of firm $i$ at time $t$ is denoted by $g^{(t)}_{i}$. Then, the single index model of the return (growth rate) is given by:\n",
    "> $$\n",
    "g^{(t)}_{i} = \\alpha_{i} + \\beta_{i}\\;g^{(t)}_{M} + \\epsilon^{(t)}_{i}\n",
    "$$\n",
    "> where $\\alpha_{i}$ is the _idiosyncratic (firm-specific) growth_, $\\beta_{i}$ is the component of the growth rate of firm $i$ explained by the market (it is also a measure of risk), $g^{(t)}_{M}$ is the growth rate of the market index at time $t$, and $\\epsilon^{(t)}_{i}$ denotes an error model associated with firm $i$ (describes growth rate not captured by the firm or market factors). \n",
    "\n",
    "Let's start by picking the ticker symbol for our test firm; we'll save this in the `my_test_ticker::String` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d61154df",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_ticker = \"PG\"; # ticker symbol for our test firm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31dc1f",
   "metadata": {},
   "source": [
    "Next, we need to pull out the growth (return) of the market portfolio from the `growth_rate_array::Array{Float64,2}` matrix.\n",
    "\n",
    "\n",
    "* We'll use the [SPDR S&P 500 ETF Trust (SPY)](https://www.ssga.com/us/en/individual/etfs/funds/spdr-sp-500-etf-trust-spy) as our market index. The SPY is an exchange-traded fund (ETF) that tracks the performance of the S&P 500 index, which is a market-capitalization-weighted index of 500 of the largest publicly traded companies in the U.S.\n",
    "\n",
    "\n",
    "To do this, look up the index for our market portfolio surrogate `SPY`, then store the growth rate (column from the growth rate array) in the `Rₘ::Array{Float64,1}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fa13403",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rₘ = findfirst(x->x==\"SPY\", list_of_tickers) |> i -> growth_rate_array[:,i];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267cc43",
   "metadata": {},
   "source": [
    "Then, we need to formulate the data matrix $\\hat{\\mathbf{X}}$ and the response vector $\\mathbf{y}$ for our test firm. The data matrix $\\hat{\\mathbf{X}} \\in \\mathbb{R}^{(T-1) \\times 2}$ will have two columns: a column of ones (to account for the intercept term $\\alpha$) and a column containing the market growth $R_{m}(t)$ values. The response vector $\\mathbf{y} \\in \\mathbb{R}^{(T-1)}$ will contain the growth values for our test firm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28c2475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X̂,y = let\n",
    "\n",
    "    # get the growth values for our test firm -\n",
    "    Rᵢ = findfirst(x-> x== my_test_ticker, list_of_tickers) |> j-> growth_rate_array[:, j];\n",
    "\n",
    "    # TODO: Build the design matrix X̂ and response vector y\n",
    "    # X̂ should have shape (T-1, 2): first column of ones, second column of market returns Rₘ\n",
    "    # y should contain the firm's returns Rᵢ\n",
    "    max_length = length(Rᵢ);\n",
    "    y = Rᵢ;\n",
    "    X̂ = [ones(max_length) Rₘ]; # <-- fill me in: [ones(...) Rₘ]\n",
    "\n",
    "    \n",
    "    X̂,y # return\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "565dd45f-571a-41bc-b394-bd0f86510b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2766×2 Matrix{Float64}:\n",
       " 1.0  -0.58454\n",
       " 1.0   0.882626\n",
       " 1.0   0.205992\n",
       " 1.0   0.0318663\n",
       " 1.0   0.300334\n",
       " 1.0  -1.33599\n",
       " 1.0   0.364513\n",
       " 1.0   2.04306\n",
       " 1.0  -0.28005\n",
       " 1.0  -0.393881\n",
       " 1.0  -0.0336959\n",
       " 1.0   0.441388\n",
       " 1.0  -1.95715\n",
       " ⋮    \n",
       " 1.0  -0.500752\n",
       " 1.0   0.945151\n",
       " 1.0  -0.971834\n",
       " 1.0  -3.77619\n",
       " 1.0  -3.04467\n",
       " 1.0   0.276633\n",
       " 1.0   1.65103\n",
       " 1.0   2.73181\n",
       " 1.0   0.7875\n",
       " 1.0  -2.71887\n",
       " 1.0  -2.4625\n",
       " 1.0  -0.920341"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X̂"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7491d7",
   "metadata": {},
   "source": [
    "Now, we can estimate the single index model parameters $\\theta=(\\alpha, \\beta)$ using ordinary least squares (OLS). The OLS estimator has the closed form solution (no regularization $\\delta=0$):\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\mathbf{\\theta}} &= \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\mathbf{y}\n",
    "\\end{align*}\n",
    "$$\n",
    "if $\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}}$ is invertible (has full column rank).  In our case, $\\hat{\\mathbf{X}}$ has two columns, so we need to check that $\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}}$ has rank 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d050b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert rank(transpose(X̂) * X̂) == 2 # check that X'X is invertible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071c8e5",
   "metadata": {},
   "source": [
    "If we get here without an error, then we know that $\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}}$ is invertible, and we can compute the single index model parameters for our test firm. Let's save these values in the $\\hat{\\mathbf{\\theta}}$ variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7218864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the normal equations solution for OLS\n",
    "# Hint: θ̂ = (X̂ᵀX̂)⁻¹X̂ᵀy\n",
    "# Use: transpose(), inv(), and matrix multiplication\n",
    "θ̂ = inv(transpose(X̂)*X̂)*transpose(X̂)*y; # <-- fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0c119b1-04f8-4b3b-98ab-f23e14d3cb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 0.014676312973311125\n",
       " 0.49051042376920384"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θ̂"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90414426",
   "metadata": {},
   "source": [
    "## Task 2: Uncertainty quantification of the single index model parameters\n",
    "In this task, we'll compute the uncertainty in our single index model parameters $\\hat{\\mathbf{\\theta}}$ for our test firm. To do this, we need to compute the standard errors of the parameter estimates $\\mathrm{SE}(\\hat{\\mathbf{\\theta}})$, which requires us to estimate the variance of the error terms $\\hat{\\sigma}^{2}$. \n",
    "\n",
    "Let's start there.\n",
    "\n",
    "> __Theory:__ Since the __true__ variance $\\sigma^2$ is unknown, we can estimate the population variance $\\hat{\\sigma}^2$ from the residuals $\\mathbf{r} = \\mathbf{y} - \\hat{\\mathbf{X}}\\hat{\\mathbf{\\theta}}$ as:\n",
    "> $$\n",
    "\\begin{align*}\n",
    "\\hat{\\sigma}^{2} &= \\left(\\frac{1}{\\Delta{t}}\\right)\\frac{\\lVert~\\mathbf{r}~\\rVert^{2}_{2}}{n-p} = \\left(\\frac{1}{\\Delta{t}}\\right)\\frac{1}{n-p}\\sum_{i=1}^{n}r_i^2\n",
    "\\end{align*}\n",
    "$$\n",
    "> where $n$ is the number of observations, $p$ is the number of parameters, $\\lVert\\star\\rVert_{2}^{2}$ denotes the $\\ell_2$ norm squared, and $r_i = y_i - \\hat{\\mathbf{x}}_i^{\\top}\\hat{\\mathbf{\\theta}}$ is the $i$-th residual, i.e., the difference between the observed and predicted value for observation $i$.\n",
    "\n",
    "We implement this computation in the code block below and save the result in the `training_variance::Float64` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "75d2ffab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(built_in_variance, my_variance) = (1238.9715663741292, 1239.4198194733954)\n"
     ]
    }
   ],
   "source": [
    "training_variance = let\n",
    "\n",
    "    # initialize -\n",
    "    p = length(θ̂); # number of parameters\n",
    "    n = size(X̂,1); # number of training observations\n",
    "    Δt  = (1/252); # time-step one-day in units of years (trading year is 252 days)\n",
    "\n",
    "    # compute the residual vector -\n",
    "    r = y .- X̂*θ̂; # residual vector\n",
    "    \n",
    "    # compute the variance using the formula from the theory box above\n",
    "    my_variance = (1/Δt)*(1/(n-p))*norm(r)^2\n",
    "\n",
    "    # let's compute the variance of the residuals (Julia) for comparison\n",
    "    built_in_variance = (1/Δt)*var(r, corrected=true); # variance - Julia\n",
    "    @show built_in_variance, my_variance; # show\n",
    "\n",
    "    my_variance; # return\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece32164",
   "metadata": {},
   "source": [
    "Next, let's compute the standard error. The standard error of the parameter estimates $\\hat{\\mathbf{\\theta}}$ quantifies the uncertainty in the estimated parameters due to the variability in the data. Let's compute the standard error for each parameter $\\hat{\\theta}_j$ that we estimated in Task 1.\n",
    "\n",
    "We save the standard errors in the `SE::Vector{Float64}` variable, where element $j$ corresponds to the standard error of a parameter estimate $\\text{SE}(\\hat{\\theta}_j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9663dec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 0.0422195602563985\n",
       " 0.01966250116372708"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE = let\n",
    "    \n",
    "    # initialize -\n",
    "    p = length(θ̂); # number of parameters\n",
    "    n = size(X̂,1); # number of training samples\n",
    "    Δt  = (1/252); # time-step one-day in units of years (trading year is 252 days)\n",
    "\n",
    "    # compute the standard error for each parameter\n",
    "    SE = sqrt.(diag(inv(transpose(X̂)*X̂))*training_variance*Δt);\n",
    "\n",
    "    SE; # return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae986ba",
   "metadata": {},
   "source": [
    "Now that we have the standard error for each of the model parameters, we can compute the uncertainty in the parameter estimates $\\hat{\\mathbf{\\theta}}$. Let's compute confidence intervals for each parameter estimate.\n",
    "> __Confidence Intervals:__ A $(1-\\alpha) \\times 100\\%$ confidence interval for each parameter $\\hat{\\theta}_j$ is given by:\n",
    "> $$\n",
    "\\begin{align*}\n",
    "\\hat{\\theta}_j \\pm t_{1-\\alpha/2,\\nu}\\; \\text{SE}(\\hat{\\theta}_j)\n",
    "\\end{align*}\n",
    "$$\n",
    "> where $t_{1-\\alpha/2,\\nu}$ is the $(1-\\alpha/2)$-quantile of a Student $t$ distribution with $\\nu$ degrees of freedom. For a 95% confidence interval, $\\alpha = 0.05$ and $t_{1-\\alpha/2,\\nu} \\approx 1.96$. For a 99.9% confidence interval, $\\alpha = 0.001$ and $t_{1-\\alpha/2,\\nu} \\approx 3.291$. The standard error $\\text{SE}(\\hat{\\theta}_j)$ (computed above) quantifies the uncertainty in the parameter estimate $\\hat{\\theta}_j$. It is given by:\n",
    ">$$\n",
    "\\begin{align*}\n",
    "\\text{SE}(\\hat{\\theta}_{j}) &= \\hat{\\sigma}\\; \\sqrt{\\bigl[(\\hat{\\mathbf X}^\\top\\hat{\\mathbf X})^{-1}\\bigr]_{jj}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Want a little more detail on confidence intervals? See this [advanced topic note](CHEME-5800-L7b-Advanced-CI-Derivation-Fall-2025.ipynb).\n",
    "\n",
    "Let's build a table that shows the parameter ranges for a 95.0% confidence interval using [the `PrettyTables.jl` package](https://github.com/ronisbr/PrettyTables.jl). (You can adjust this to show another confidence interval if you like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5c0ac394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== ========= ========= ========= ========= =========\n",
      " \u001b[1m     i \u001b[0m \u001b[1m feature \u001b[0m \u001b[1m       p \u001b[0m \u001b[1m       l \u001b[0m \u001b[1m       u \u001b[0m \u001b[1m     cz \u001b[0m\n",
      " \u001b[90m Int64 \u001b[0m \u001b[90m  String \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m String \u001b[0m\n",
      "======== ========= ========= ========= ========= =========\n",
      "      1         α    0.0147   -0.0681    0.0974      yes\n",
      "      2         β    0.4905     0.452     0.529       no\n",
      "======== ========= ========= ========= ========= =========\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    # initialize -\n",
    "    t = 1.96; # for a 95% confidence interval\n",
    "    df = DataFrame(); # hold the data (rows) for the table\n",
    "\n",
    "    # build features of the table -\n",
    "    feature_labels = Array{String,1}();\n",
    "    push!(feature_labels, \"α\");\n",
    "    push!(feature_labels, \"β\");\n",
    "\n",
    "    for i ∈ eachindex(θ̂)\n",
    "\n",
    "        center = θ̂[i];\n",
    "        lower_bound = θ̂[i] - t*SE[i];\n",
    "        upper_bound = θ̂[i] + t*SE[i];\n",
    "\n",
    "        row_df = (\n",
    "            i = i,\n",
    "            feature = feature_labels[i],\n",
    "            p = round(center, digits=4),\n",
    "            l = round(lower_bound, digits=4),\n",
    "            u = round(upper_bound, digits=4),\n",
    "            cz = (lower_bound <= 0.0 <= upper_bound ? \"yes\" : \"no\")\n",
    "        ) # data for the row\n",
    "\n",
    "        push!(df, row_df) # add the row to the dataframe\n",
    "    end\n",
    "\n",
    "    # show the table -\n",
    "    pretty_table(df, backend = :text,\n",
    "        table_format = TextTableFormat(borders = text_table_borders__simple)) # new table API. Hmmm\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced4a08",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83594c",
   "metadata": {},
   "source": [
    "## Task 3: SVD-Based Parameter Estimation\n",
    "\n",
    "In the previous tasks, we used the normal equations approach: $\\hat{\\mathbf{\\theta}} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y}$. However, this approach can be numerically unstable when the data matrix $\\hat{\\mathbf{X}}$ has a high condition number (multicollinearity). \n",
    "\n",
    "Let's use **Singular Value Decomposition (SVD)** to estimate the parameters more robustly.\n",
    "\n",
    "> **Theory:** If $\\hat{\\mathbf{X}} = \\mathbf{U}\\mathbf{S}\\mathbf{V}^{\\top}$ is the SVD decomposition of $\\hat{\\mathbf{X}}$, then the least squares solution becomes:\n",
    "> $$\\hat{\\mathbf{\\theta}} = \\mathbf{V}\\mathbf{S}^{+}\\mathbf{U}^{\\top}\\mathbf{y}$$\n",
    "> where $\\mathbf{S}^{+}$ is the Moore-Penrose pseudoinverse of the diagonal matrix $\\mathbf{S}$. This approach is more numerically stable and handles rank-deficient matrices gracefully.\n",
    "> \n",
    "> For practical computation, this can be written in index notation as:\n",
    "> $$\n",
    "\\boxed{\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\theta}} = \\sum_{i=1}^{r_{\\hat{X}}}\\left(\\frac{\\mathbf{u}_{i}^{\\top}\\mathbf{y}}{\\sigma_{i}}\\right)\\mathbf{v}_{i}\\quad\\blacksquare\n",
    "\\end{equation*}}\n",
    "$$\n",
    "> where $r_{\\hat{X}} = \\min(n,p)$ is the rank of the data matrix $\\hat{\\mathbf{X}}$, $\\mathbf{u}_{i}$ and $\\mathbf{v}_{i}$ are the $i$-th columns of $\\mathbf{U}$ and $\\mathbf{V}$, respectively, and $\\sigma_{i}$ is the $i$-th singular value (with $\\sigma_i > 0$).\n",
    "\n",
    "Ok, so let's play around with this. First, let's compute the SVD of our data matrix $\\hat{\\mathbf{X}}$ from Task 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "73384f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "U,S,V = svd(X̂);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "93d577fb-9c73-46ac-9976-668ce265947c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 112.96598769316324\n",
       "  52.51079224392125"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f4f773",
   "metadata": {},
   "source": [
    "The SVD decomposition gives us three matrices: $\\mathbf{U}$ (left singular vectors), $\\mathbf{S}$ (singular values), and $\\mathbf{V}$ (right singular vectors). Now, let's compute the individual parameter modes that make up the final estimate. Each mode corresponds to one singular value and captures how that singular component contributes to the overall parameter vector.\n",
    "\n",
    "We'll store these in the `parameter_modes::Dict{Int, Array{Float64,1}}` dictionary, where each key is the singular value index and each value is the corresponding parameter contribution $(\\mathbf{u}_i^{\\top}\\mathbf{y}/\\sigma_i)\\mathbf{v}_i$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "87e1f4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Vector{Float64}} with 2 entries:\n",
       "  2 => [0.000274155, -8.04949e-6]\n",
       "  1 => [0.0144022, 0.490518]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_modes = let\n",
    "    \n",
    "    # initialize -\n",
    "    r = rank(X̂); # rank of the design matrix\n",
    "    parameter_modes = Dict{Int, Array{Float64,1}}(); # create an empty dictionary\n",
    "    \n",
    "    # TODO: Loop through each singular value and compute the parameter contribution\n",
    "    # Hint: For each i, compute (uᵢᵀy/σᵢ) * vᵢ and store in parameter_modes[i]\n",
    "    for i ∈ 1:r\n",
    "        u = U[:,i]; # i-th left singular vector\n",
    "        v = V[:,i]; # i-th right singular vector\n",
    "        σ = S[i]; # i-th singular value\n",
    "        parameter_modes[i] = ((transpose(u)*y)/σ)*v; # <-- fill me in: ((transpose(u)*y)/σ)*v\n",
    "    end\n",
    "\n",
    "    parameter_modes; # return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02916acf",
   "metadata": {},
   "source": [
    "Now, we can reconstruct the parameter estimates using the SVD components. Let's implement the SVD-based parameter estimation and compare it to our previous OLS estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "381d126c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 0.014402158050404176\n",
       " 0.4905184732571335"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θ̂_svd = let\n",
    "\n",
    "    # TODO: Reconstruct the full parameter estimate by summing all modes\n",
    "    # Hint: Start with a zero vector, then add each parameter_modes[i]\n",
    "    # You can use r = rank(X̂) or r = 2 (since we have 2 parameters)\n",
    "    r = rank(X̂); # or simply use r = 2\n",
    "    p = zero(θ̂); # initialize parameter estimate as zero vector\n",
    "\n",
    "    r = 1\n",
    "    # TODO: Sum up all the parameter modes\n",
    "    for i ∈ 1:r\n",
    "        p += parameter_modes[i] # <-- fill me in\n",
    "    end\n",
    "    \n",
    "    p; # return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f854e",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40402f2",
   "metadata": {},
   "source": [
    "Let's compare our SVD-based estimate `θ̂_svd` with the normal equations estimate `θ̂` to verify they match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3779c7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "θ̂ = [0.014676312973311125, 0.49051042376920384]\n",
      "θ̂_svd = [0.014402158050404176, 0.4905184732571335]\n",
      "θ̂ ≈ θ̂_svd = false\n"
     ]
    }
   ],
   "source": [
    "@show θ̂; # Normal equations estimate\n",
    "@show θ̂_svd; # SVD-based estimate\n",
    "@show θ̂ ≈ θ̂_svd; # Should be true (approximately equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae05b8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this lab, we estimated single index models for S&P500 firms using both the normal equations approach and SVD-based methods, comparing parameter estimates and quantifying uncertainty through confidence intervals.\n",
    "\n",
    "> __Key Takeaways:__\n",
    "> \n",
    "> * **Full column rank confirms independent firm behavior**: Our growth rate matrix having rank 424 tells us that no firm's returns can be perfectly predicted from the others, justifying individual parameter estimation for each stock despite potential correlations.\n",
    ">\n",
    "> * **Confidence intervals reveal statistical significance**: By computing standard errors and confidence intervals, we can determine whether our alpha estimates reflect genuine firm-specific returns or merely capture noise—critical for distinguishing meaningful abnormal returns from statistical artifacts.\n",
    ">\n",
    "> * **SVD provides robust alternatives to direct inversion**: While mathematically equivalent for well-conditioned problems, the SVD approach offers superior numerical stability through the pseudoinverse, making it the preferred method when dealing with near-singular matrices or multicollinearity common in financial data.\n",
    "\n",
    "These dual-method parameter estimation techniques form the foundation for empirical asset pricing and portfolio construction in modern quantitative finance.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb65700-e3d9-4811-a179-87f823bcc8ee",
   "metadata": {},
   "source": [
    "## Disclaimer and Risks\n",
    "\n",
    "__This content is offered solely for training and informational purposes__. No offer or solicitation to buy or sell securities or derivative products or any investment or trading advice or strategy is made, given, or endorsed by the teaching team.\n",
    "\n",
    "__Trading involves risk__. Carefully review your financial situation before investing in securities, futures contracts, options, or commodity interests. Past performance, whether actual or indicated by historical tests of strategies, is no guarantee of future performance or success. Trading is generally inappropriate for someone with limited resources, investment or trading experience, or a low-risk tolerance. Only risk capital that is not required for living expenses.\n",
    "\n",
    "__You are fully responsible for any investment or trading decisions you make__. Such decisions should be based solely on evaluating your financial circumstances, investment or trading objectives, risk tolerance, and liquidity needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.7",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
